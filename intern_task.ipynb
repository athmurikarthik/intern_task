{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary liberaries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import zipfile\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting data\n",
    "os.listdir('C:/Users/User/Downloads/dataset/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []\n",
    "imgs = 'C:/Users/User/Downloads/dataset/data'\n",
    "for img in (os.listdir(imgs)):\n",
    "  image = Image.open(img)\n",
    "  data = asarray(image)\n",
    "  image1 = Image.fromarray(data)\n",
    "  img_array = cv2.imread(image1)\n",
    "  new = cv2.resize(img,(512,512))\n",
    "  new_data.append(new)\n",
    "return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data splitting\n",
    "x_train =new_data()[:2500]\n",
    "x_test = np.random.shuffle(new_data()[:1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data resizing\n",
    "x_train = np.reshape(x_train, (len(x_train), 512, 512, 3)) / 255.\n",
    "x_test = np.reshape(x_test, (len(x_test), 512, 512, 3)) / 255.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Training\n",
    "model = Sequential()\n",
    "\n",
    "input_shape = (512, 512, 3)\n",
    "# Encoder layers\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same',input_shape=input_shape))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "\n",
    "model.add(Conv2D(8, (3, 3), activation='sigmoid', padding='same'))\n",
    "#decoder layers\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(3, (3, 3), activation='sigmoid', padding='same'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 30\n",
    "batch_size = 64\n",
    "train_batch_size = 1000\n",
    "train_batch_per_epoch = math.ceil(x_train.shape[0] / train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=7, init ='k-means++', max_iter=300, n_init=10,random_state=0 )\n",
    "kmeans1 = kmeans.fit_predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualisation\n",
    "plt.scatter(x_test[kmeans1==0, 0], x_test[kmeans1==0, 1], s=100, c='red', label ='Cluster 1')\n",
    "plt.scatter(x_test[kmeans1==1, 0], x_test[kmeans1==1, 1], s=100, c='blue', label ='Cluster 2')\n",
    "plt.scatter(x_test[kmeans1==2, 0], x_test[kmeans1==2, 1], s=100, c='green', label ='Cluster 3')\n",
    "plt.scatter(x_test[kmeans1==3, 0], x_test[kmeans1==3, 1], s=100, c='cyan', label ='Cluster 4')\n",
    "plt.scatter(x_test[kmeans1==4, 0], x_test[kmeans1==4, 1], s=100, c='magenta', label ='Cluster 5')\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300, c='yellow', label = 'Centroids')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(x_train, x_train,epochs=1,batch_size=batch_size,shuffle=True,validation_data=(x_test[0:200], x_test[0:200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result visualisation\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('training loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_imgs = model.predict(x_test)\n",
    "encoder = Model(inputs=model.input, outputs=model.get_layer('code').output)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder to get the 'codes' for each image\n",
    "coded_imgs = encoder.predict(x_test)\n",
    "coded_imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the 'cosine similarity' as a measure \n",
    "# each of the first ten image codes\n",
    "similar = np.zeros((n,n))\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        rel = cosine(coded_imgs[i], coded_imgs[j])\n",
    "        similar[i,j] = rel\n",
    "ax = sns.heatmap(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 90\n",
    "plt.imshow(x_test[img_idx].reshape(28,28))\n",
    "src_img_code = coded_imgs[img_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_similar_images(idx):\n",
    "    src_img_code = coded_imgs[idx]\n",
    "\n",
    "    # calculate the cosine similarity from our reference image to all the other image codes\n",
    "    similarities = [ (cosine(src_img_code, coded_imgs[i]), i) for i in range(len(coded_imgs)) ]\n",
    "    similarities.sort()\n",
    "    similar_idxs = [ i for _,i in similarities ]\n",
    "\n",
    "    # plot top 10 matches\n",
    "    plt.figure(figsize=(20,4))\n",
    "    for i, idx in enumerate(similar_idxs[:n]):\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        ax.axis('off')\n",
    "        if i == 0:\n",
    "          ax.set_title(\"Original\")\n",
    "        else:\n",
    "          ax.set_title(idx)\n",
    "        plt.imshow(x_test[idx].reshape(28,28))\n",
    "\n",
    "\n",
    "for i in [10, 20, 30, 40, 50, 60]:\n",
    "    find_similar_images(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
